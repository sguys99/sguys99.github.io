<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Search Result</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />

    <!--custom.css-->
    <link rel="stylesheet" type="text/css" href="/assets/built/custom.css" />

    <!-Font Awesome-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <!--웹폰트 추가-->
    <link rel="stylesheet" href="https://fonts.googleapis.com/earlyaccess/nanumgothic.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300&display=swap" />

    <!--syntax.css 추가-->
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />


    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="Data science, Machine learning, and Automatic control" />
    <link rel="shortcut icon" href="https://sguys99.github.io//assets/images/logo.png" type="image/png" />
    <link rel="canonical" href="https://sguys99.github.io//search" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="Happy Plant" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Search Result" />
    <meta property="og:description" content="Data science, Machine learning, and Automatic control" />
    <meta property="og:url" content="https://sguys99.github.io//search" />
    <meta property="og:image" content="https://sguys99.github.io//assets/images/main-cover.jpg" />
    <meta property="article:publisher" content="https://www.facebook.com/dbrhkdaud" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Search Result" />
    <meta name="twitter:description" content="Data science, Machine learning, and Automatic control" />
    <meta name="twitter:url" content="https://sguys99.github.io//" />
    <meta name="twitter:image" content="https://sguys99.github.io//assets/images/main-cover.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Happy Plant" />
    <meta name="twitter:site" content="@sguys99" />
    <meta name="twitter:creator" content="@sguys99" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="666" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "Happy Plant",
        "logo": "https://sguys99.github.io//"
    },
    "url": "https://sguys99.github.io//search",
    "image": {
        "@type": "ImageObject",
        "url": "https://sguys99.github.io//assets/images/main-cover.jpg",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://sguys99.github.io//search"
    },
    "description": "Data science, Machine learning, and Automatic control"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Search Result" href="/feed.xml" />


</head>
<body class="page-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- < default -->
<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<!-- The big featured header, it uses blog cover image as a BG if available -->
<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="https://sguys99.github.io//">Happy Plant</a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-data-science" role="menuitem"><a href="/tag/data-science/">Data Science</a></li>
    <li class="nav-algorithmic-trading" role="menuitem"><a href="/tag/algorithmic-trading/">Trading</a></li>
    <li class="nav-python" role="menuitem"><a href="/tag/it-tips/">It Tips</a></li>
    <li class="nav-diary" role="menuitem"><a href="/tag/diary/">Diary</a></li>
    <!-- 주석
    <li class="nav-goto-turtles3040" role="menuitem"><a href="https://github.com/turtles3040">turtles3040</a></li>
    -->
    <li class="nav-archive" role="menuitem">
        <a href="/archive.html">All Posts</a>
    </li>
    <li class="nav-archive" role="menuitem">
        <a href="/author_archive.html">Posts by Tag</a>
    </li>
</ul>

        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
                <a class="social-link social-link-fb" href="https://facebook.com/dbrhkdaud" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
</a>
            
            
            <a class="social-link social-link-tw" href="https://www.github.com/sguys99" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-github" viewBox="0 0 16 16">
  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
</svg></a>
            
            
            <a class="social-link social-link-tw" href="https://www.linkedin.com/in/kmyu99" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1"  width="24" height="24" viewBox="0 0 24 24"><path fill="#FFFFFF" d="M21,21H17V14.25C17,13.19 15.81,12.31 14.75,12.31C13.69,12.31 13,13.19 13,14.25V21H9V9H13V11C13.66,9.93 15.36,9.24 16.5,9.24C19,9.24 21,11.28 21,13.75V21M7,21H3V9H7V21M5,3A2,2 0 0,1 7,5A2,2 0 0,1 5,7A2,2 0 0,1 3,5A2,2 0 0,1 5,3Z" /></svg></a>
            
            
                <a class="social-link social-link-tw" href="https://twitter.com/sguys99" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Search</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  post page no-image">

            <header class="post-full-header">
                <h1 class="post-full-title">Search Result</h1>
            </header>

            

            <section class="post-full-content">
                <form action="/search" method="get" hidden="hidden">
    <label for="search-box"></label>
    <input type="text" id="search-box" name="query">
</form>

<ul class="mylist" id="search-results"></ul>

<script>
    window.store = {
    
    "it01": {
        "title": "git cheat sheet1",
            "author": "km.yu99",
            "category": "",
            "content": "이 포스트는 여러 절로 구성되어 있습니다.   cheat sheet1 - 기본 명령어git 기본 명령어와 옵션 별 기능을 정리하였다.1. Setup  git init : 저장소(repository) 생성  git clone [원격 저장소 url] : 해당 주소의 내용을 복제하여 저장소 생성  git config user.name [작성자 이름] : 작성자 이름 설정  git config user.email [이메일 계정] : 작성자 이메일 설정  git config --list : 저장소 설정 전체 출력  git config --get [설정항목] : 일부 설정항목만 출력(ex : git config –get user.name)  git help [커맨드 이름] : 도움말2. Stage &amp; commit  git add [파일이름] : 수정된 파일을 staging area 올리기  git add [디렉토리 명] : 해당 디렉토리 내에 수정된 모든 파일들을 staging area에 올리기  git add . : working directory 내에 수정된 모든 파일들을 staging area에 올리기 (untracked 파일 제외)  git commit : 이력 저장(commit)  git commit -m \"[메시지]\" : vim을 사용하지 않고 인라인으로 메시지를 추가하여 commit  git commit -am \"[메시지]\" : add와 commit을 일괄적으로 진행3. Inspectgit status  git status : 저장소 파일의 상태정보 출력  git status -s : 파일 상태정보를 간략하게 표시git log  git log : 저장소의 commit이력을 출력  git log --pretty=oneline : 각 commit을 한줄로 출력(–pretty 옵션 사용)  git log --oneline : 각 commit을 한줄로 출력  git log --decorate=full : 브랜치나 태그정보를 상세히 출력  git log --graph : 그래프 형태로 출력git show  git show : 가장 최근의 commit 정보 출력  git show [commit hash] : 해당 commit의 정보 출력  git show HEAD : HEAD가 참조하는 commit의 정보 출력  git show HEAD^^^ : HEAD를 기준으로 3단계 이전의 commit정보 출력  git show HEAD~[n] : HEAD를 기준으로 n단계 이전의 commit정보 출력git diff  git diff : 최근 commit과 변경사항이 발생한(Unstaged) 파일들의 내용비교  git diff --staged : 최근 commit과 Staging area의 파일들 간의 변경사항 출력  git diff [commit hash1] [commit hash2] : 두 commit의 파일들 간의 변경사항 출력",
        "url": "/it01"
    }
    ,
    
    "ds1": {
        "title": "custom dataset으로 YOLOv5 학습하기",
            "author": "km.yu99",
            "category": "",
            "content": "YOLO(You Only Look Once)는 널리 쓰이는 object detection 알고리즘이다. 최근에는 YOLOv5 까지 출시되었다. 여기서는 공식 github 계정에 업로드된 YOLOv5 코드로 custom dataset을 학습하는 방법에 대하여 설명한다. google colab 환경에서 진행되었다.1. 데이터셋 소개실습에 사용되는 데이터셋은 roboflow에서 제공되는 North American Mushrooms Dataset이다.[링크]여기서는 학습시간을 줄이기 위해서 416x416 사이즈의 이미지 51장을 다운 받았다.object detection 알고리즘 라이브러리 구현방식에 따라, 그리고 YOLO 버전 별로도 사용하는 레이블링 파일의 포맷이 다르다. roboflow에서는 레이블링 파일 포맷을 선택하여 다운도르 할 수 있다. 우리는 PyTorch로 구현된 공식 계정의 코드를 사용할 예정이므로 YOLO v5 PyTorch를 선택하고 다운로드 한다.참고로 YOLOv5 공식계정의 코드는 txt 포맷의 레이블링 데이터를 사용한다.이 파일은 이미지에서 검출된 object에 대한 클래스와 bounding box 정보를 포함하고 있다. 검출 객체정보 배치는 [class, x_center, y_center, width, height] 형태로 되어있다. bounding box 정보는 이미지 사이즈에 의해 정규화 되어있다. 따라서 0~1 범위의 값을 가진다.편의를 위해 다운로드한 데이터 셋 압축파일의 폴더 이름을 custom_dataset으로 수정한다. 데이터 폴더 구성은 다음과 같다.custom_dataset│├── test/│   ├── images/                    │   └── labels/             │├── train/│   ├── images/                │   └── labels/               │├── valid/│   ├── images/                    │   └── labels/   │├── data.yaml└── README.dataset.txtdata.yaml파일을 메모장으로 열어보자. 데이터 셋 기본정보가 포함되어 있다. 우리는 *.yaml 파일을 새로 만들 것이다. 어떤 식으로 구성되는지 참고만 한다.train과 val은 각 데이터 셋의 경로정보이다. 그리고 nc는 class의 수(number of classes)를, names는 각 클래스의 이름이다.2. colab에서 환경구축하기google colab에 접속하고 새 노트를 생성한다. 런타임-런타임 유형 변경을 선택하여, 하드웨어 가속기를 GPU로 설정한다.이제 colab 노트에 공식 github 계정의 파일을 다운로드하고, 필수 라이브러리를 설치하는 명령을 입력한다.!git clone https://github.com/ultralytics/yolov5  # yolov5 코드 clone%cd yolov5 \t\t\t\t\t\t\t\t\t\t  # clone한 폴더로 진입%pip install -qr requirements.txt                 # 필수 라이브러리 설치Cloning into 'yolov5'...remote: Enumerating objects: 10354, done.remote: Total 10354 (delta 0), reused 0 (delta 0), pack-reused 10354Receiving objects: 100% (10354/10354), 10.58 MiB | 23.75 MiB/s, done.Resolving deltas: 100% (7149/7149), done./content/yolov5     |████████████████████████████████| 596 kB 5.4 MB/s 파일 탐색기에 yolov5 폴더가 생성되었고, 파일들이 다운로드 되어있다.이제 앞에서 다운로드한 데이터셋을 업로드 한다. 파일 탐색기의 업로드 아이콘을 클릭하여 custom_dataset.zip 파일을 업로드 한다.업로드가 완료되면 탐색기에 해당 파일이 표시된다.unzip 명령으로 데이터 셋 파일의 압축을 해제한다.!unzip ../custom_dataset.zipArchive:  ../custom_dataset.zip  inflating: custom_dataset/data.yaml    inflating: custom_dataset/README.dataset.txt    inflating: custom_dataset/README.roboflow.txt     creating: custom_dataset/test/   creating: custom_dataset/test/images/  inflating: custom_dataset/test/images/chanterelle_02_jpg.rf.f7a48494b7393c532f641585d99a57be.jpg    inflating: custom_dataset/test/images/chanterelle_03_jpg.rf.580f8d787af6a8050c21c065bf016f20.jpg    inflating: custom_dataset/test/images/chanterelle_03_jpg.rf.cd892d2f06d228ba20d194fc360320fc.jpg    --- (생 략)완료되면 yolov5/custom_dataset/ 경로에 데이터 셋이 위치하게 된다. (현 작업 디렉토리가 yolov5이기 때문)마지막으로 데이터 셋 설정파일을 작성한다.` yolov5/data/ 폴더에 custom_dataset.yaml`이라는 이름의 파일을 생성한다.여기에 다음과 같이 설정정보를 입력한다.path: /content/yolov5/custom_dataset  #root 디렉토리train: train/images\t\t\t\t\t  # 학습데이터 경로val: valid/imagestest: test/imagesnc: 2\t\t\t\t\t\t\t\t# 클래스 수names: ['CoW', 'chanterelle']\t\t# 클래스 이름자세한 내용은 다음 링크의 **1.1 Create dataset.yaml** 항목을 참고하자.이로써 학습을 위한 모든 준비가 완료 되었다.3. 모델 학습하기모델 학습 순서는 다음과 같다.위와 같은 일련의 과정은 train.py  파일 실행을 통해 가능하다. 인자로 학습 데이터 경로와 epoch 수를 입력하고 학습을 진행하자.!python train.py --data \"data/custom_dataset.yaml\" --epochs 100 #epoch 100회 Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf... train: weights=yolov5s.pt, cfg=, data=data/custom_dataset.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=100, batch_size=16, imgsz=640, '''  ---(생략)  Overriding model.yaml nc=80 with nc=2                   from  n    params  module                                  arguments                        0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]                 1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                   2                -1  1     18816  models.common.C3                        [64, 64, 1]    ---(생략)  Logging results to runs/train/exp Starting training for 100 epochs...       Epoch   gpu_mem       box       obj       cls    labels  img_size       0/99     3.23G    0.1252   0.03226   0.02699        28       640: 100% 3/3 [00:05&lt;00:00,  1.95s/it]                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00&lt;00:00,  2.48it/s]                  all          5         14    0.00695      0.311    0.00395     0.0011        ---(생략)  Validating runs/train/exp/weights/best.pt... Fusing layers...  Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs                Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00&lt;00:00,  4.48it/s]                  all          5         14       0.95      0.996      0.973      0.697                  CoW          5          5          1      0.991      0.995      0.688          chanterelle          5          9      0.899          1      0.951      0.706 Results saved to runs/train/exp학습이 완료되면 runs/train/exp경로에 학습 결과가 저장된다. 학습을 반복하면 runs/train경로에 exp1, 2, 3… 같은 형태로 폴더가 생성되면서 학습 결과가 기록된다.학습 결과를 다운로드 하고 싶다면 zip 명령을 압축한 뒤, 저장한다 . 예를 들어 train_result.zip이라는 이름으로 압축하고 싶다면 다음과 같이 입력한다.!zip -r train_result.zip /content/yolov5/runs/train/exp탐색기에 train_result.zip가 표시되면 정상으로 압축된 것이다.4. 학습한 모델 검증하기이제 학습한 모델로 검증을 진행해보자. 검증순서는 앞의 학습 절차에서 모델 가중치 업데이트 과정이 생략된 것이다.모델 검증은 val.py  파일 실행을 통해 진행한다. 다양한 인자가 있지만 데이터 경로(--data), 모델 가중치(--weights) 정도만 입력해서 실행해보자. 앞에서 학습한 모델 가중치는 runs/train/exp/weights/best.pt에 저장되었다.!python val.py --data \"data/custom_dataset.yaml\" --weights \"/content/yolov5/runs/train/exp/weights/best.pt\"val: data=data/custom_dataset.yaml, weights=['/content/yolov5/runs/train/exp/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=FalseYOLOv5 🚀 v6.0-155-gdc54ed5 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)Fusing layers... Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPsval: Scanning '/content/yolov5/custom_dataset/valid/labels.cache' images and labels... 5 found, 0 missing, 0 empty, 0 corrupted: 100% 5/5 [00:00&lt;?, ?it/s]               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00&lt;00:00,  2.58it/s]                 all          5         14      0.909      0.982      0.961      0.686                 CoW          5          5          1      0.965      0.995      0.672         chanterelle          5          9      0.818          1      0.926        0.7Speed: 0.6ms pre-process, 29.3ms inference, 3.0ms NMS per image at shape (32, 3, 640, 640)Results saved to runs/val/exp검증결과는 runs/val/exp에 저장된다. 앞에서와 마찬가지로 다운로드 받고 싶다면 폴더를 압축하자.!zip -r val_result.zip /content/yolov5/runs/valexp 폴더 안에는 confusion matrix, F1 curve 등 성능과 관련된 차트가 저장되어 있다.5. 학습한 모델로 예측하기예측과정은 아래 그림과 같은 절차로 진행된다.예측 과정은 detect.py 파일을 사용한다. 단순 이미지 뿐만 아니라 웹캠, 비디오 파일 등에서도 실행 가능하다. --source인자에 다음과 같이 설정해주면 된다.!python detect.py --source 0  # webcam                            img.jpg  # image                            vid.mp4  # video                            path/  # directory                            path/*.jpg  # glob                            'https://youtu.be/Zgi9g1ksQHc'  # YouTube                            'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream여기서는 custom_dataset/test/images 경로에 있는 이미지에 대해서 object detection을 실행해본다. 인식 대상 (--source), 모델 가중치(--weights)  경로를 입력해서 실행해보자.!python detect.py --weights \"/content/yolov5/runs/train/exp/weights/best.pt\" --source \"/content/yolov5/custom_dataset/test/images\"detect: weights=['/content/yolov5/runs/train/exp/weights/best.pt'], source=/content/yolov5/custom_dataset/test/images, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, ---(생략)Fusing layers... Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPsimage 1/5 /content/yolov5/custom_dataset/test/images/chanterelle_02_jpg.rf.f7a48494b7393c532f641585d99a57be.jpg: 640x640 3 chanterelles, Done. (0.034s)--- (생략)테스트 결과는 /runs/detect/exp 경로에 저장된다. 결과를 다운로드 하고 싶다면 다음과 같이 압축하여 저장한다.!zip -r test_result.zip /content/yolov5/runs/detect/exp폴더를 열어보면 class와 bounding box가 표시된 detection 결과 이미지가 저장되어 있다.",
        "url": "/ds1"
    }
    ,
    
    "trading2": {
        "title": "KRX에서 종목코드 가져오기2",
            "author": "km.yu99",
            "category": "",
            "content": "한국거래소(KRX)에서 증권과 관련된 데이터와 통계정보를 제공하는 정보데이터시스템 웹페이지가 있다.여기서도 상장주식의 종목코드 리스트를 가져올 수 있다.1. 홈페이지 둘러보기KRX의 전자정보데이터시스템에 접속한다.  http://data.krx.co.kr/contents/MDC/MAIN/main/index.cmd‘주식’-‘종목정보’-‘전종목 지정내역’ 또는 [다음] 링크를 클릭한다.해당 화면에서 국내 상장주식의 기본정보를 조회할 수 있다. 우측에 다운로드 아이콘을 클릭하면 원하는 포맷으로 데이터를 다운로드 할수도 있다.크롬에서 ‘F12’버튼 또는 마우스 우클릭 후 ‘검사’를 클릭하여 개발자 도구 창을 연다.상단 탭에서 ‘Network’를 선택한다. 이 상태에서 앞에서 설명한 다운로드 항목에서 ‘CSV’ 아이콘을 클릭하여 파일 다운로드를 실행해본다.개발자 도구창 하단에 ‘generate.cmd’, ‘download.cmd’가 새로 생성되었다.즉, 파일 다운로드 과정은 두단계를 거치게 된다. ‘generate.cmd’에 의해서 데이터를 다운로드 하기 위한 code를 리턴한다. 이 후 ‘download.cmd’로 code를 파라미터로 하여 데이터를 저장한다.‘generate.cmd’를 선택하고 상단의 ‘Headers’를 클릭해보자.요청할 주소와 방식(POST) 등을 확인할 수 있다.‘Payload’를 클릭하면 요청할 때 사용된 파라미터를 확인된다.마찬가지로 ‘download.cmd’를 선택하고 상단의 ‘Headers’를 클릭해보자.요청할 주소와 방식(POST)을 확인할 수 있다.‘Payload’에는 code 값이 표시되어 있다. 이 값은 ‘generate.cmd’로 받아와야 하는 값이다.이 정보를 바탕으로 코드를 작성한다.2. 추출하기웹에서 정보를 가져오기 위해 requests 라이브러리를 사용할 것이다.필요한 라이브러리를 import 한다.import requestsimport pandas as pdfrom io import BytesIO첫번째 단계로 generate 요청을 진행한다.요청할 주소와 파라미터를 설정하자. 앞에 소개한 ‘generate.cmd’에 명시된 내용이다.gen_url = 'http://data.krx.co.kr/comm/fileDn/GenerateOTP/generate.cmd'gen_parms = {    'mktId': 'ALL',    'share': '1',    'csvxls_isNo': 'false',    'name': 'fileDown',    'url': 'dbms/MDC/STAT/standard/MDCSTAT01901'    }python 코드에 의한 접근이 아닌 크롬으로 접근하고 있음을 표시하기 위해 header 정보를 추가한다. ‘Headers’ 하단에 있는 ‘Request Headers’ 항목을 참고하여 작성한다.headers = {    'Referer': 'http://data.krx.co.kr/contents/MDC/MDI/mdiLoader/index.cmd?menuId=MDC0201020101',    'Upgrade-Insecure-Requests': '1',    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36' #generate.cmd에서 찾아서 입력하세요    }code 값을 리턴받기 위해 요청을 진행한다.r = requests.get(url=gen_url, params=gen_parms, headers=headers)r.contentb'a1n6kaOi+6ccSQWhSJQn6cmnCCnJIeb940e8ATaeiE4RtSksuLS7Bnxpl86F7dAOvXfGx9S2U5wgvoxsacATRRtmGtORI4WrGDmruVe6oXtCqUypoW0Lp6SAPP0PhVkgThCTcjIZNPI5lCTubZnhjio6AHXdxc45YVEhz4JdugHPMxvIwHadpQpCGE1HxZAXvTCprTIXuXT9XxFb88awpQ=='r.content에 code 값이 저장되었다.이제 두번째 단계, 다운로드 요청을 진행한다.‘download.cmd’에 표시된 요청주소를 참고하고, code는 앞에서 받은 값을 지정한다.down_url = 'http://data.krx.co.kr/comm/fileDn/download_csv/download.cmd'data = {    'code': r.content}r = requests.post(url=down_url, data=data, headers=headers)r.content이렇게 받은 정보는 바이너리 데이터이다.이 데이터를 다루기 위해 BytesIO 메서드를 사용한다.이제 pandas의 read_csv 메서드로 데이터를 읽어온다.stock_code = pd.read_csv(BytesIO(r.content), encoding='cp949')stock_code.head()필요한 컬럼만 가져오고 컬럼명을 영문으로 변경한다.stock_code = stock_code[['한글 종목약명', '단축코드', '시장구분', '액면가', '상장주식수']]stock_code = stock_code.rename(columns = {'시장구분': 'market', '한글 종목약명': 'name', '단축코드': 'code',                                           '액면가': 'par_value', '상장주식수': 'total_shrs'})stock_code.head()                  name      code      market      par_value      total_shrs                  0      마이크로컨텍솔      098120      KOSDAQ      500      8312766              1      스카이이앤엠      131100      KOSDAQ      500      11642629              2      포스코엠텍      009520      KOSDAQ      500      41642703              3      AJ네트웍스      095570      KOSPI      1000      46822295              4      AK홀딩스      006840      KOSPI      5000      13247561      3. 함수로 정리하기def get_krx_code():    gen_url = 'http://data.krx.co.kr/comm/fileDn/GenerateOTP/generate.cmd'    gen_parms = {        'mktId': 'ALL',        'share': '1',        'csvxls_isNo': 'false',        'name': 'fileDown',        'url': 'dbms/MDC/STAT/standard/MDCSTAT01901'        }    headers = {    'Referer': 'http://data.krx.co.kr/contents/MDC/MDI/mdiLoader/index.cmd?menuId=MDC0201020101',    'Upgrade-Insecure-Requests': '1',    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36' #generate.cmd에서 찾아서 입력하세요    }    r = requests.get(url=gen_url, params=gen_parms, headers=headers)        down_url = 'http://data.krx.co.kr/comm/fileDn/download_csv/download.cmd'    data = {        'code': r.content    }    r = requests.post(url=down_url, data=data, headers=headers)        stock_code = pd.read_csv(BytesIO(r.content), encoding='cp949')    stock_code = stock_code[['한글 종목약명', '단축코드', '시장구분', '액면가', '상장주식수']]    stock_code = stock_code.rename(columns = {'시장구분': 'market', '한글 종목약명': 'name', '단축코드': 'code',                                               '액면가': 'par_value', '상장주식수': 'total_shrs'})        return stock_code",
        "url": "/trading2"
    }
    ,
    
    "trading1": {
        "title": "KRX에서 종목코드 가져오기1",
            "author": "km.yu99",
            "category": "",
            "content": "1. 홈페이지 둘러보기먼저 KRX 홈페이지(https://kind.krx.co.kr/) 를 방문하여 ‘상장법인상세정보’/ ‘상장법인목록’ 화면으로 이동한다.(또는 [다음] 링크를 클릭한다.)‘EXECEL’ 버튼을 클릭하면 전체 상장법인 목록을 다운받을 수 있다.다운로드한 파일은 ‘xls’ 확장자를 가지고 있지만 html 포맷이다. 우리는 파이썬 코드로 위 목록을 가져와 pandas 데이터프레임으로 변환하고자 한다.다시 돌아와서 상장법인 목록을 다운로드 하는 방식을 살펴보자.‘시장구분’, ‘검색유형’ 등과 같은 범주를 설정하고 ‘EXCEL’ 버튼을 클릭하면 해당 범주에 해당하는 법인목록이 다운로드 되는 방식이다.설정항목을 수정하지 않고 EXCEL 버튼을 클릭하면 전체 상장법인 목록이 다운로드 된다.크롬에서 해당 페이지를 열고 ‘상장법인목록’ 부분을 마우스 우클릭하고, ‘검사’ 항목을 선택하자.검색 항목의 소스를 확인할 수 있다.요약하면 ‘searchForm’이라고 하는 양식을 통해서 추출 조건을 지정한다. 그리고 ‘post’를 사용해서 데이터 추출을 요청한다.추출 처리를 담당하는 서버의 주소는 ‘http://kind.krx.co.kr/corpgeneral/corpList.do’ 이다.그리고 ‘EXCEL’ 버튼을 클릭했을 때, 동작하는 메커니즘을 살펴보자.버튼을 클릭하면 ‘fnDownolad()’ 함수를 호출한다.이 함수는 searchForm에 설정된 조건대로 데이터를 다운로드 하도록 서버 프로그램에 요청하는 함수이다.2. 추출하기다운되는 종목코드 파일이 html 형식이므로 pandas의 read_html 함수를 사용한다.read_html의 인자에 다운로드를 요청할 url을 지정하면 된다.서버의 url 뒤에 ‘?’로 url의 끝을 표시하고 데이터(검색조건)를 추가하면 된다.주요 조건은 다음과 같다.  method: 메서드, 예시) ‘download’  orderMode:정렬컬럼, 예시) ‘1’,  orderStat: 정렬 내림차순, 예시) ‘D’  searchType: 검색유형, 예시) ‘13’(상장법인)  fiscalYearEnd: 결산원, 예시) ‘all’(전체)  location: 지역, 예시) ‘all’(전체)여기서는 다음과 같이 설정한다. (나머지는 default 값 적용)url = 'http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&amp;searchType=13'import pandas as pdimport numpy as npimport osstock_code = pd.read_html(url, header = 0)[0] # 주의 : [0]을 반드시 추가. read_html은 table들을 읽어 리스트로 저장함stock_code.head()                  회사명      종목코드      업종      주요제품      상장일      결산월      대표자명      홈페이지      지역                  0      DL      210      기타 금융업      지주회사      1976-02-02      12월      전병욱      http://www.dlholdings.co.kr      서울특별시              1      DRB동일      4840      고무제품 제조업      고무벨트(V벨트,콘베이어벨트,평벨트),프라스틱제품 제조,판매      1976-05-21      12월      류영식      http://drbworld.com      부산광역시              2      DSR      155660      1차 비철금속 제조업      합섬섬유로프      2013-05-15      12월      홍석빈      http://www.dsr.com      부산광역시              3      GS      78930      기타 금융업      지주회사/부동산 임대      2004-08-05      12월      허태수, 홍순기 (각자 대표이사)      NaN      서울특별시              4      GS글로벌      1250      상품 종합 도매업      수출입업(시멘트,철강금속,전기전자,섬유,기계화학),상품중개,광업,채석업/하수처리 서...      1976-06-26      12월      김태형      http://www.gsgcorp.com      서울특별시      국내 주식시장의 종목코드는 6자리 이다. 예를 들어 ‘DL’의 종목코드는 000210이다.그런데 저장된 종목코드는 앞자리 0이 생략되어 있다. map함수로 6자리를 완성한다.# 종목코드가 6자리이기 때문에 6자리를 맞춰주기 위해 설정해줌stock_code['종목코드'] = stock_code['종목코드'].map('{:06d}'.format)stock_code.head()                  회사명      종목코드      업종      주요제품      상장일      결산월      대표자명      홈페이지      지역                  0      DL      000210      기타 금융업      지주회사      1976-02-02      12월      전병욱      http://www.dlholdings.co.kr      서울특별시              1      DRB동일      004840      고무제품 제조업      고무벨트(V벨트,콘베이어벨트,평벨트),프라스틱제품 제조,판매      1976-05-21      12월      류영식      http://drbworld.com      부산광역시              2      DSR      155660      1차 비철금속 제조업      합섬섬유로프      2013-05-15      12월      홍석빈      http://www.dsr.com      부산광역시              3      GS      078930      기타 금융업      지주회사/부동산 임대      2004-08-05      12월      허태수, 홍순기 (각자 대표이사)      NaN      서울특별시              4      GS글로벌      001250      상품 종합 도매업      수출입업(시멘트,철강금속,전기전자,섬유,기계화학),상품중개,광업,채석업/하수처리 서...      1976-06-26      12월      김태형      http://www.gsgcorp.com      서울특별시      분석에 필요한 컬럼만 추출하고, 컬럼명을 영어로 수정한다.stock_code = stock_code[['회사명', '종목코드', '업종', '주요제품', '상장일', '결산월']]stock_code = stock_code.rename(columns = {'회사명': 'name', '종목코드': 'code', '업종': 'sectors','주요제품': 'products',                                         '상장일': 'listing_date', '결산월': 'closing_date'})stock_code['listing_date'] = pd.to_datetime(stock_code['listing_date'])stock_code.head()                  name      code      sectors      products      listing_date      closing_date                  0      DL      000210      기타 금융업      지주회사      1976-02-02      12월              1      DRB동일      004840      고무제품 제조업      고무벨트(V벨트,콘베이어벨트,평벨트),프라스틱제품 제조,판매      1976-05-21      12월              2      DSR      155660      1차 비철금속 제조업      합섬섬유로프      2013-05-15      12월              3      GS      078930      기타 금융업      지주회사/부동산 임대      2004-08-05      12월              4      GS글로벌      001250      상품 종합 도매업      수출입업(시멘트,철강금속,전기전자,섬유,기계화학),상품중개,광업,채석업/하수처리 서...      1976-06-26      12월      stock_code.shape(2486, 6)3. 함수로 정리하기def get_krx_code():    url = 'http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&amp;searchType=13'    stock_code = pd.read_html(url, header = 0)[0]    stock_code['종목코드'] = stock_code['종목코드'].map('{:06d}'.format)    stock_code = stock_code[['회사명', '종목코드', '업종', '주요제품', '상장일', '결산월']]    stock_code = stock_code.rename(columns = {'회사명': 'name', '종목코드': 'code', '업종': 'sectors','주요제품': 'products',                                              '상장일': 'listing_date', '결산월': 'closing_date'})    stock_code['listing_date'] = pd.to_datetime(stock_code['listing_date'])        return stock_code",
        "url": "/trading1"
    }
    ,
    
    "foody3": {
        "title": "(서울 송파 맛집) 평이담백뼈칼국수",
            "author": "km.yu99",
            "category": "",
            "content": "평이담백뼈칼국수 방이점  주 소 :  서울 송파구 위례성대로18길 31-12  영업시간 : 11:30 ~ 21:00(브레이크타임 15~17)  전화번호 : 02-417-7488  대표메뉴 : 뼈칼국수(10,000원), 비빔칼국수(9,000원), 새우만두(6,000원)이번에  소개할 가게는 망원에 본점을 둔 칼국수 체인이다. 돼지고기 등뼈를 칼국수 육수로 사용해서 색다른 맛을 느낄 수 있기에 추천해본다. 가게는 방이역 4번출구 인근에 위치해있다. 가게 앞에 3~4대 정도 주차할 수 있는 공간이 있다.  체인이라서 실내 인테리어도 깔끔하다.주력메뉴는 뼈칼국수와 비빔국수이다. 가격은 약깐 비싸다고 느껴질 수 있겠다. 하지만 맛이 보장된다면 용납할 수 있을 정도다. 한가지만 주문하기 애매해서 뼈칼국수와 비빔칼국수 하나씩 주문했다.뼈칼국수는 고기가 듬뿍 얹혀져서 나온다. 국물도 가볍지 않다. 개인적으로 퍼진 면발을 좋아하지 않는데, 면발이 상당히 쫄깃하다.뼈에 붙은 고기의 양도 상당하다. 뼈해장국처럼 매운양념이 되어있지 않아서 고기 맛이 다소 심심할 수도 있다. 이 때는 함께 나오는 소스에 고기를 찍어 먹어보자.비빔칼국수. 갈아진 돼지고기와 고소한 콩가루가 들어간다. 양념장이 맵지도 않고 적당하다. 뼈칼국수를 시킬지 비빔국수를 시킬지, 방문할 때마다 고민될 것 같다.여유가 된다면 새우만두도 함께 먹어보자. 4개에 6000원으로 다소 비싸보일 수도 있다. 얇은 만두피 안에 새우가 가득차있어 진한 풍미를 느낄 수있다.날씨가 쌀쌀해지면 뜨끈한 국물이 생각날때가 있다. 순대국의 든든함과 쫄깃한 면발을 함께 경험하고 싶다면 한번 방문해보자.총 평  음식맛 : ★★★☆☆  가성비 : ★★★☆☆  서비스 : ★★★☆☆  접근성 : ★★★★☆",
        "url": "/foody3"
    }
    ,
    
    "foody2": {
        "title": "(서울 송파 맛집) 차고버거",
            "author": "km.yu99",
            "category": "",
            "content": "방이동 먹자골목 수제버거 전문점. 차고버거  주 소 :  서울시 송파구 오금로 61-11  영업시간 : 11:30 ~ 22:00(목~금, 브레이크타임 15~17), 11:30 ~ 22:00(토), 11:30 ~ 21:00(일), 월요일 휴무  전화번호 : 0507-1410-0601  대표메뉴 : ** **차고 클래식(7,900원), 하와이안(8,900원), 에그룸(9,900원), 칠리 치즈 프라이(8,800원)내가 사는 방이동 인근에는 식당들이 많다. 석촌 호수를 끼고 조성된 까페들과 양식집들. 최근에 사람들이 몰리고 있는 송리단길. 그리고 오래 전부터 주점들이 들어서 있었던 먹자골목 까지.오늘 소개할 곳은 방이동 먹자골목에 위치한 차고버거. 먹자골목 메인 식당가에서는 떨어져 있다. 개인적으로는 이 위치가 더 마음에 든다. 지하철역에서 가깝고 사람들로 붐비지 않아 편하게 이동할 수 있다.이 가게는 포장이나 배달도 가능하지만 본연의 맛을 느끼기 어렵다. 햄버거는 식어버리면 맛이 급격하게 떨어진다. 특히 프렌치 프라이가 박스안에 같혀서 오래 있으면 고소하고 바삭거리는 식감을 내기 힘들다. 오늘은 큰맘먹고 매장에서 식사를 했다.입구는 넓어 보이지만 매장안에 테이블은 얼마 안된다. 입구 쪽을 확장해서 테이블을 몇개 더 두었다.에그롬과 로코모코, 그리고 하우스커피 한잔을 주문했다.에그룸에는 패티, 베이컨, 계란 후라이가 들어간다. 일반적인 버거 내용물에 계란이 들어 가서 그런지 부드러운 맛이 더해졌다. 하지만 이 구성에 단품 9,900원은 약간 부담스럽다.괌 여행을 갔을 때 처음 먹어본 로코모코. 기본 이상은 해준다. 남자 기준으로 양은 약간 부족한 편.양이 부족한 것 같아 치즈 프라이도 하나 주문했다. 포장해왔을 때는 눅눅해져서 다 먹지 못했는데 확실히 매장에서 먹는 것이 맛있다.요즘 수제버거 가게가 많이 생겨서 흔한 맛이지만, 고깃집과 술집이 대부분인 방이동 먹자골목에서는 흔치 않은 소중한 식당이다.총 평  음식맛 : ★★★☆☆  가성비 : ★★★☆☆  서비스 : ★★★☆☆  접근성 : ★★★★☆",
        "url": "/foody2"
    }
    ,
    
    "foody1": {
        "title": "(서울, 과천 맛집) 메밀장터",
            "author": "km.yu99",
            "category": "",
            "content": "지하철 4호선 선바위역에 위치한 막국수 맛집. 메밀장터  주 소 :  경기 과천시 뒷골로 5-7 선바위  영업시간 : 10:40 ~ 21:20(매일)  전화번호 : 02-504-0122  주요메뉴 : 들기름 막국수(9,000원), 명태회 막국수(9,000원)지하철역 인근에 있어서 도보로 이동가능하다.점심시간을 피해 오후 2시 이후에 방문하면 기다리지 않고 입장할 수 있다.아래 사진의 통로로 들어오면 가게 앞 주차장이 있다. 주차공간은 넓지 않은 편이다.사람들이 몰리는 시간대를 피해서 갔지만 주차할 공간이 없어서 인근에 주차해야 했다.식당 안에는 앉아서 식사할 수 있는 방과 테이블이 있다. 테이블은 만석이라 방으로 이동했다.이 곳의 대표 메뉴는 들기름 막국수이다. 개인적으로 비빔국수를 좋아해서 들기름 막국수, 명태회 막국수 하나씩 주문했다.비주얼은 나름 괜찮다. 면 색깔로 보아 메밀이 많이 포함된 것 같아 보이진 않았다.들기름 막국수. 계란 반쪽과 들깨 가루 고명, 들기름이 양념의 전부이다. 과연 이것으로 맛을 낼수 있을까?국수를 잘 비벼서 한젓갈 입에 넣어본다. 입안에 들기름의 고소함이 퍼진다. 지금까지 맛본 들기름 중에 단연 고소함이 으뜸이다.명태회 막국수도 괜찮다. 명태회가 충분이 들어있고 양념장도 간이 잘되어 있다.하지만 역시 이집의 으뜸은 들기름 막국수. 호불호가 갈릴수도 있지만, 두명이서 온다면 들기름, 명태회 막국수 하나씩 시켜서 쉐어하는 것도 괜찮아 보인다. 들기름 국수 면을 90% 정도 건저 먹은 후, 함께 나오는 동치미 국물을 조금 부어서 먹어보자. 이 또한 색다른 맛이다.물 막국수, 비빔 막국수에 익숙한 나에게 들기름 막국수의 세계로 안내한 가게였다.총 평  음식맛 : ★★★★☆  가성비 : ★★★☆☆  서비스 : ★★★☆☆  접근성 : ★★★★☆",
        "url": "/foody1"
    }
    ,
    
    "trading1": {
        "title": "Test for algorithmic-trading1",
            "author": "km.yu99",
            "category": "",
            "content": "머신러닝 강좌는 여러 절로 구성되어 있습니다.     ml시작    ml 강좌(1) - 지도, 비지도 학습첫번째 강좌를 시작합니다.루즈를 사용한 자바스크립트 코드function syntaxHighlight(code) {   var foo = 'Hello World';   var bar = 100;}루즈를 사용한 파이썬 코드import pandas as pdimport numpy as npdef func(url):    data = pd.read_csv(url):    return dataimport pandas as pdimport numpy as npdef func(url):    data = pd.read_csv(url):    return data",
        "url": "/trading1"
    }
    ,
    
    "ml1": {
        "title": "첫번째 강좌",
            "author": "km.yu99",
            "category": "",
            "content": "머신러닝 강좌는 여러 절로 구성되어 있습니다.     ml시작    ml 강좌(1) - 지도, 비지도 학습첫번째 강좌를 시작합니다.루즈를 사용한 자바스크립트 코드function syntaxHighlight(code) {   var foo = 'Hello World';   var bar = 100;}루즈를 사용한 파이썬 코드import pandas as pdimport numpy as npdef func(url):    data = pd.read_csv(url):    return dataimport pandas as pdimport numpy as npdef func(url):    data = pd.read_csv(url):    return data",
        "url": "/ml1"
    }
    ,
    
    "ds1": {
        "title": "Test for data science1",
            "author": "km.yu99",
            "category": "",
            "content": "머신러닝 강좌는 여러 절로 구성되어 있습니다.     ml시작    ml 강좌(1) - 지도, 비지도 학습첫번째 강좌를 시작합니다.루즈를 사용한 자바스크립트 코드function syntaxHighlight(code) {   var foo = 'Hello World';   var bar = 100;}루즈를 사용한 파이썬 코드import pandas as pdimport numpy as npdef func(url):    data = pd.read_csv(url):    return dataimport pandas as pdimport numpy as npdef func(url):    data = pd.read_csv(url):    return data",
        "url": "/ds1"
    }
    ,
    
    "trading2": {
        "title": "Test for algorithmic-trading2",
            "author": "km.yu99",
            "category": "",
            "content": "Welcome to machine learning basics!!",
        "url": "/trading2"
    }
    ,
    
    "ml-basics": {
        "title": "Starting machine learning posts",
            "author": "km.yu99",
            "category": "",
            "content": "머신러닝 강좌는 여러 절로 구성되어 있습니다.     ml시작    ml 강좌(1) - 지도, 비지도 학습Welcome to machine learning basics!!",
        "url": "/ml-basics"
    }
    ,
    
    "ds2": {
        "title": "Test for data science2",
            "author": "km.yu99",
            "category": "",
            "content": "Welcome to machine learning basics!!",
        "url": "/ds2"
    }
    
    
    };
</script>
<script src="assets/js/lunr.js"></script>
<script src="assets/js/search.js"></script>
            </section>

        </article>

    </div>
</main>

<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->
<script>
$(function() {
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
});
</script>



        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://sguys99.github.io//">Happy Plant</a> &copy; 2021</section>
                <section class="poweredby">Published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    <a href="https://facebook.com/dbrhkdaud" target="_blank" rel="noopener">Facebook</a>
                    <!--
                    <a href="https://twitter.com/sguys99" target="_blank" rel="noopener">Twitter</a>
                    -->
                    <a href="https://www.linkedin.com/in/kmyu99" target="_blank" rel="noopener">LinkedIn</a>
                    <a href="https://github.com/sguys99" target="_blank" rel="noopener">Github</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
    <div id="subscribe" class="subscribe-overlay">
        <a class="subscribe-overlay-close" href="#"></a>
        <div class="subscribe-overlay-content">
            
            <h1 class="subscribe-overlay-title">Search Happy Plant</h1>
            <p class="subscribe-overlay-description">
                lunr.js를 이용한 posts 검색 </p>
            <span id="searchform" method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  />
    <input class="location" type="hidden" name="location"  />
    <input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" onkeyup="myFunc()"
               id="searchtext" type="text" name="searchtext"
               placeholder="Search..." />
    </div>
    <script type="text/javascript">
        function myFunc() {
            if(event.keyCode == 13) {
                var url = encodeURIComponent($("#searchtext").val());
                location.href = "/search.html?query=" + url;
            }
        }
    </script>
</span>

        </div>
    </div>
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-69281367-1', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>
$(function() {
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
